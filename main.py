import numpy as np
import pandas as pd
import re
import ast
from typing_extensions import override
from collections import Counter
import nltk
nltk.download('wordnet')
from nltk.corpus import wordnet
import requests
from tqdm import tqdm
from transliterate import translit
from catboost import CatBoostRegressor
import time
import os
import pickle
import flask
import functions_framework

save_dir = 'models'
n_models = 5  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π

seeds = [42, 100, 2024, 999, 777]

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–¥ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–æ–º
loaded_models = []
for seed in seeds:
    model_path = os.path.join(save_dir, f"catboost_model_{seed}_2.cbm")
    model = CatBoostRegressor()
    model.load_model(model_path)
    loaded_models.append(model)
    print(f"‚úÖ –ú–æ–¥–µ–ª—å {seed} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {model_path}")    

def evaluate_special_characters_length(string):
    if string is None:
        return 0
    special_chars = re.findall(r"[^a-zA-Z0-9\s@]", string)
    return len(special_chars)


def evaluate_number_length(string):
    if string is None:
        return 0
    numbers = re.findall(r"\d", string)
    return len(numbers)


def has_special_characters(string):
    if string is None:
        return 0
    return 1 if re.search(r"[^a-zA-Z0-9\s@]", string) else 0


def has_numbers(string):
    if string is None:
        return 0
    return 1 if re.search(r"\d", string) else 0


def most_frequent_char_count(string):
    if string is None or string == '':
        return 0
    return Counter(string).most_common(1)[0][1]


def is_english_word_wordnet(word: str) -> int:
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    word_lower = word.lower()
    return 1 if len(wordnet.synsets(word_lower)) > 0 else 0  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º 1 –∏–ª–∏ 0


with open('translit_cache.pkl', 'rb') as f:
    translit_words = pickle.load(f)


# –§—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —é–∑–µ—Ä–Ω–µ–π–º–∞
def is_translit(username):
    return 1 if username.lower() in translit_words else 0  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º 1 –∏–ª–∏ 0


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ –∫ API
def get_valuations(domain):
    url = 'https://valuation.humbleworth.com/api/valuation'
    headers = {'Content-Type': 'application/json'}
    response = requests.post(url, json={'domains': [domain]}, headers=headers)
    if response.status_code == 200:
        return response.json().get('valuations', [])
    else:
        print(f"–û—à–∏–±–∫–∞: {response.status_code}")
        return []


url = 'https://api.coingecko.com/api/v3/simple/price'
params = {
    'ids': 'the-open-network',
    'vs_currencies': 'usd'
}
response = requests.get(url, params=params)

if response.status_code == 200:
    data = response.json()

course = data['the-open-network']['usd']


def get_data(username):
    start_time = time.time()

    # data = process_username(username)
    data = pd.DataFrame({'username': [username]})
    data['length'] = data['username'].apply(lambda x: len(x) if x is not None else 0)
    data['special_characters_length'] = data['username'].apply(evaluate_special_characters_length)
    data['numbers_length'] = data['username'].apply(evaluate_number_length)
    data['has_special_characters'] = data['username'].apply(has_special_characters)
    data['has_numbers'] = data['username'].apply(has_numbers)
    data['max_char_repeats'] = data['username'].apply(most_frequent_char_count)
    data['IsInDictionary_2'] = data['username'].apply(is_english_word_wordnet)
    data['is_translit'] = data['username'].apply(is_translit)

    # username = data['username'].iloc[0]
    domain = f"{username}.com"  # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–æ–º–µ–Ω
    valuations = get_valuations(domain)
    if valuations:
        valuation_data = valuations[0]  # –ü–µ—Ä–≤—ã–π (–∏ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π) —ç–ª–µ–º–µ–Ω—Ç –≤ —Å–ø–∏—Å–∫–µ
        data['auction'] = valuation_data.get('auction', None)
        data['brokerage'] = valuation_data.get('brokerage', None)
        data['marketplace'] = valuation_data.get('marketplace', None)
    else:
        # –ï—Å–ª–∏ API –Ω–µ –≤–µ—Ä–Ω—É–ª –¥–∞–Ω–Ω—ã–µ, –¥–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç–æ–ª–±—Ü—ã
        data['auction'] = None
        data['brokerage'] = None
        data['marketplace'] = None

    end_time = time.time()
    total_time = end_time - start_time
    print(f"–û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_time:.4f} —Å–µ–∫")
    return data


# def predict(X_test):
#     predictions = np.array([model.predict(X_test) for model in loaded_models])
#     uncertainty = np.std(predictions)
#     pred_mean = max(1, np.mean(predictions))  # –ó–∞—â–∏—Ç–∞ –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0
#     confidence_score = (1 - uncertainty / pred_mean) * 100
#     confidence_score = np.clip(confidence_score, 0, 100)

#     result = "=" * 40

#     print("=" * 40)
#     result += "\n" + "üìå –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π:"
#     print("üìå –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π:")
#     for i, pred in enumerate(predictions, 1):
#         pred_value = pred.item() if isinstance(pred, np.ndarray) else float(pred)  # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ –∏–∑ –º–∞—Å—Å–∏–≤–∞
#         pred_ton = pred_value  # –í TON
#         pred_usd = pred_value * course  # –í USD

#         result += f"\n  –ú–æ–¥–µ–ª—å {i}: {pred_ton:,.2f} TON ({pred_usd:,.2f} USD)"
#         print(f"  –ú–æ–¥–µ–ª—å {i}: {pred_ton:,.2f} TON ({pred_usd:,.2f} USD)")

#     result += "\n" + "-" * 40
#     print("-" * 40)

#     uncertainty_ton = uncertainty
#     uncertainty_usd = uncertainty * course
#     pred_mean_ton = pred_mean
#     pred_mean_usd = pred_mean * course

#     result += f"\nüìä –†–∞–∑–±—Ä–æ—Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {uncertainty_ton:,.2f} TON ({uncertainty_usd:,.2f} USD)"
#     print(f"üìä –†–∞–∑–±—Ä–æ—Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {uncertainty_ton:,.2f} TON ({uncertainty_usd:,.2f} USD)")

#     result += f"\nüìà –°—Ä–µ–¥–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {pred_mean_ton:,.2f} TON ({pred_mean_usd:,.2f} USD)"
#     print(f"üìà –°—Ä–µ–¥–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {pred_mean_ton:,.2f} TON ({pred_mean_usd:,.2f} USD)")

#     result += f"\nüîπ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: {confidence_score:.2f}%"
#     print(f"üîπ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: {confidence_score:.2f}%")

#     result += "\n" + "=" * 40
#     print("=" * 40)
    
#     return result

# @functions_framework.http
# def helloWorld(request: flask.Request) -> flask.typing.ResponseReturnValue:
#     print(request.json)
#     X_test = get_data(request.json["username"]).iloc[:, 1:]
#     return predict(X_test)

def predict(X_test, username):
    predictions = np.array([model.predict(X_test) for model in loaded_models])
    uncertainty = np.std(predictions)
    pred_mean = max(1, np.mean(predictions))  # –ó–∞—â–∏—Ç–∞ –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0
    confidence_score = (1 - uncertainty / pred_mean) * 100
    confidence_score = np.clip(confidence_score, 0, 100)

    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    result = {
        "username": username,
        "priceInUSD": float(pred_mean * course),
        "priceInTon": float(pred_mean),
        "confidence": float(confidence_score),
        "score": float(pred_mean)  # –ï—Å–ª–∏ score –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —á–µ–º-—Ç–æ –¥—Ä—É–≥–∏–º, —É–∫–∞–∂–∏—Ç–µ –∫–∞–∫ –µ–≥–æ –≤—ã—á–∏—Å–ª—è—Ç—å
    }
    
    return result

@functions_framework.http
def helloWorld(request: flask.Request) -> flask.typing.ResponseReturnValue:
    print(request.json)
    username = request.json["username"]
    X_test = get_data(username).iloc[:, 1:]
    prediction_result = predict(X_test, username)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∫ JSON
    return flask.jsonify(prediction_result)